{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design a Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 295.Find Median from Data Stream </b>\n",
    "\n",
    "The add operation for heapq is Log(N)  \n",
    "Find median is to keep 2 heap, with same length, one keep smaller value, another keep larger value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class MedianFinder:\n",
    "    def __init__(self):\n",
    "        \"\"\"initialize the data structure, left to keep half smaller num, right to keep another half larger number\"\"\"\n",
    "        self.left = []\n",
    "        self.right = []\n",
    "    def addNum(self, num):\n",
    "        if len(self.left) == len(self.right):\n",
    "            # consider adding to right part with priority\n",
    "            # to ensure left part pop out large value first, save the number as negative value\n",
    "            # always ensure self.right has num >= self.left\n",
    "            heapq.heappush(self.right, -heapq.heappushpop(self.left, -num))\n",
    "        else:\n",
    "            # same the so far smallest number to left part\n",
    "            heapq.heappush(self.left, -heapq.heappushpop(self.right, num))\n",
    "   \n",
    "    def findMedian(self):\n",
    "        if len(self.right) == len(self.left):\n",
    "            # CANT use pop! next time the value is no longer there to consider median\n",
    "#             return (heapq.heappop(self.right)-heapq.heappop(self.left))/2\n",
    "            return (self.right[0]-self.left[0])/2\n",
    "        else:\n",
    "#             return heapq.heappop(self.right)\n",
    "            return self.right[0]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "obj = MedianFinder()\n",
    "obj.addNum(1)\n",
    "obj.addNum(2)\n",
    "print(obj.findMedian()) \n",
    "obj.addNum(3)\n",
    "print(obj.findMedian()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>146. LRU Cache </b>  \n",
    "\n",
    "Least Recently Used cache. get( ) and push( ) are all O(1)   \n",
    "because of O(1) => dictionary as hashmap.   \n",
    "for tracking if it is least recently used, use posistion. => orderedDict  or Double linked List\n",
    "\n",
    "For OrderedDict in python,  \n",
    "popitem: by default it treats the dict as a stack, LIFO, if given param last=False => FIFO.   \n",
    "move_to_end: move to the end of space like the item is newly added. if given param last=False => move to the beginning of the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# class Node:\n",
    "#     \"\"\"double linked list\"\"\"\n",
    "#     def __init__(self, key, val):\n",
    "#         self.key = key\n",
    "#         self.val = val\n",
    "#         self.prev = None\n",
    "#         self.next = None\n",
    "    \n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "    \n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "            return self.cache[key]\n",
    "        else:\n",
    "            return -1\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            del self.cache[key]\n",
    "        self.cache[key] = value\n",
    "        if len(self.cache) > self.capacity:\n",
    "            self.cache.popitem(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = LRUCache( 2 );\n",
    "\n",
    "cache.put(1, 1);\n",
    "cache.put(2, 2);\n",
    "cache.get(1);       # returns 1\n",
    "cache.put(3, 3);    # evicts key 2\n",
    "cache.get(2);       # returns -1 (not found)\n",
    "cache.put(4, 4);    # evicts key 1\n",
    "cache.get(1);       # returns -1 (not found)\n",
    "cache.get(3);       # returns 3\n",
    "cache.get(4);       # returns 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(3, 3), (4, 4)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is how to implement the double linked list by self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"double linked list\"\"\"\n",
    "    def __init__(self, k, v):\n",
    "        self.key = k\n",
    "        self.val = v\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.head = Node(0, 0)  # assume 0 is not a valid value from user input\n",
    "        self.tail = Node(0, 0)\n",
    "        self.head.next = self.tail  # imagine two nodes connected, become double linked list\n",
    "        self.tail.prev = self.head\n",
    "        self.cache = {}  # a dict of double linked list\n",
    "        \n",
    "    def _remove(self, node):\n",
    "        \"\"\"get rid of the linkage when deleting the node\"\"\"\n",
    "        prev_node = node.prev\n",
    "        next_node = node.next\n",
    "        prev_node.next = next_node\n",
    "        next_node.prev = prev_node\n",
    "        \n",
    "    def _add(self, node):\n",
    "        \"\"\"add the new node to the tail of the list, so nodes in the tail direction are recently used nodes\"\"\"\n",
    "        prev_node = self.tail.prev\n",
    "        node.prev = prev_node\n",
    "        node.next = self.tail\n",
    "        prev_node.next = node\n",
    "        self.tail.prev = node\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            node = self.cache[key]\n",
    "            self._remove(node)\n",
    "            self._add(node)  # recently used, should be moved to tail\n",
    "            return node.val\n",
    "        else:\n",
    "            return -1\n",
    "            \n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            node = self.cache[key]\n",
    "            self._remove(node)\n",
    "        node = Node(key, value)\n",
    "        self._add(node)\n",
    "        self.cache[key] = node\n",
    "        if len(self.cache) > self.capacity:\n",
    "            del_node = self.head.next # the least recently used node is located near head\n",
    "            self._remove(del_node)\n",
    "            del self.cache[del_node.key]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: <__main__.Node at 0x7f88f9a322e0>, 4: <__main__.Node at 0x7f88f9a2f640>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache = LRUCache( 2 );\n",
    "\n",
    "cache.put(1, 1);\n",
    "cache.put(2, 2);\n",
    "cache.get(1);       # returns 1\n",
    "cache.put(3, 3);    # evicts key 2\n",
    "cache.get(2);       # returns -1 (not found)\n",
    "cache.put(4, 4);    # evicts key 1\n",
    "cache.get(1);       # returns -1 (not found)\n",
    "cache.get(3);       # returns 3\n",
    "cache.get(4);       # returns 4\n",
    "cache.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 155 Min Stack </b>  \n",
    "\n",
    "How to store the min value is the key of this question. when a new number, which we'll call x, is placed on a Stack, the numbers below it will not change for as long as number x remains on the Stack. whenever number x is the top of the Stack, the minimum will always be the same, as it's simply the minimum out of x and all the numbers below it.\n",
    "\n",
    "So save the value and min value at that time together\n",
    "\n",
    "the time complexity for push, pop, top, getmin are all O(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinStack:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.stack = []\n",
    "        \n",
    "\n",
    "    def push(self, x: int) -> None:\n",
    "        if not self.stack:\n",
    "            min_val = x\n",
    "        else:\n",
    "            min_val = min(x, self.stack[-1][-1])\n",
    "        self.stack.append((x, min_val))\n",
    "        \n",
    "        \n",
    "    def pop(self) -> None:\n",
    "        return self.stack.pop()[0]\n",
    "\n",
    "    def top(self) -> int:\n",
    "        return self.stack[-1][0]\n",
    "\n",
    "    def getMin(self) -> int:\n",
    "        return self.stack[-1][-1]\n",
    "\n",
    "\n",
    "# Your MinStack object will be instantiated and called as such:\n",
    "# obj = MinStack()\n",
    "# obj.push(x)\n",
    "# obj.pop()\n",
    "# param_3 = obj.top()\n",
    "# param_4 = obj.getMin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "obj = MinStack()\n",
    "obj.push(3)\n",
    "obj.push(4)\n",
    "print(obj.top())\n",
    "print(obj.getMin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 295 find Median from data stream </b>\n",
    "\n",
    "Both the heaps are balanced (or nearly balanced)  \n",
    "The max-heap contains all the smaller numbers while the min-heap contains all the larger numbers  \n",
    "\n",
    "how to balancing the two heaps are the key. That is why the heapq.heappushpop() method is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class MedianFinder:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.left = []\n",
    "        self.right = []\n",
    "    def addNum(self, num: int) -> None:\n",
    "        # using -1 to reverse the order \n",
    "        # add value to left part if two list have same amount of num\n",
    "        if len(self.left)==len(self.right):\n",
    "            heapq.heappush(self.left, -1*heapq.heappushpop(self.right, num))\n",
    "        else:\n",
    "            # left is longer, so add to right to keep balance\n",
    "            heapq.heappush(self.right, -1*heapq.heappushpop(self.left, -1*num))\n",
    "        \n",
    "    def findMedian(self) -> float:\n",
    "        # even number, get largest value out of left part and smallest value out of right part\n",
    "        if len(self.left)==len(self.right):\n",
    "            return (-1*self.left[0]+self.right[0])/2\n",
    "        else:\n",
    "            return -1*self.left[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "obj = MedianFinder()\n",
    "obj.addNum(1)\n",
    "obj.addNum(2)\n",
    "print(obj.findMedian())\n",
    "obj.addNum(3)\n",
    "print(obj.findMedian())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 297 Serialize and Deseriazlie Binary Tree </b>. \n",
    "\n",
    "The genius part is to use iter() and next() when constructing the tree back.  \n",
    "in this way the list of node value is used in the same order as how the list is constructed when doing pre-order-traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for a binary tree node.\n",
    "class TreeNode(object):\n",
    "    def __init__(self, x):\n",
    "        self.val = x\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "class Codec:\n",
    "    def serialize(self, root):\n",
    "        \"\"\"Encodes a tree to a single string.\n",
    "        \n",
    "        :type root: TreeNode\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        def pre_order_traversal(node):\n",
    "            # preorder makes it easy to know where the root node locates\n",
    "            if not node:\n",
    "                res.append(\"X\")\n",
    "            else:\n",
    "                res.append(str(node.val))  # cant use join on [int]\n",
    "                pre_order_traversal(node.left)\n",
    "                pre_order_traversal(node.right)\n",
    "        \n",
    "        res = []\n",
    "        pre_order_traversal(root)\n",
    "        return \" \".join(res)  # into string\n",
    "    def deserialize(self, data):\n",
    "        \"\"\"Decodes your encoded data to tree.\n",
    "        \n",
    "        :type data: str\n",
    "        :rtype: TreeNode\n",
    "        \"\"\"\n",
    "        # if not using next, can use list.pop(0) or deque.popleft() \n",
    "        def build_tree():\n",
    "            val = next(vals) # smart to use next!!!\n",
    "            if val == \"X\":\n",
    "                return None\n",
    "            else:\n",
    "                node = TreeNode(int(val))\n",
    "                node.left = build_tree() # next will get the next value in list\n",
    "                node.right = build_tree()\n",
    "                return node\n",
    "        vals = iter(data.split())  # into a iterable!!\n",
    "        root = build_tree()\n",
    "        return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>449. Serialize and Deserialize BST</b>\n",
    "\n",
    "exactly the same as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for a binary tree node.\n",
    "# class TreeNode:\n",
    "#     def __init__(self, x):\n",
    "#         self.val = x\n",
    "#         self.left = None\n",
    "#         self.right = None\n",
    "\n",
    "class Codec:\n",
    "\n",
    "    def serialize(self, root):\n",
    "        \"\"\"Encodes a tree to a single string.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "\n",
    "        def _helper(node):\n",
    "            \"\"\"pre-order traversal\"\"\"\n",
    "            if not node:\n",
    "                res.append(\"x\")\n",
    "                return\n",
    "            res.append(str(node.val))\n",
    "            _helper(node.left)\n",
    "            _helper(node.right)\n",
    "            \n",
    "        _helper(root)\n",
    "        return ','.join(res)\n",
    "\n",
    "    def deserialize(self, data):\n",
    "        \"\"\"Decodes your encoded data to tree.\n",
    "        \"\"\"\n",
    "        # example data: 4,3,2,x,x,x,7,6,x,x\n",
    "        \n",
    "        def _helper(data):\n",
    "            # data is an interable, so using next can get the correct next value for child node\n",
    "            val = next(data)\n",
    "            if val!=\"x\":\n",
    "                node = TreeNode(int(val)) \n",
    "            else: \n",
    "                return None\n",
    "            node.left = _helper(data)\n",
    "            node.right = _helper(data)\n",
    "            return node\n",
    "        data = iter(data.split(\",\"))\n",
    "        root = _helper(data)\n",
    "        return root\n",
    "\n",
    "# Your Codec object will be instantiated and called as such:\n",
    "# codec = Codec()\n",
    "# codec.deserialize(codec.serialize(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 348. design tic-tac-toe </b>\n",
    "\n",
    "use 2 list of ints to track each row and col's count, and 2 numbers to track the count in diagnol and anti-diagnol.  \n",
    "if player 1, add 1, if player 2, add -1. if the abs value == the size, there must be some place (either row, or col or diagonal) having full marks, the player must be the one who just made a move.\n",
    "\n",
    "smart points:  \n",
    "1. player A use 1, player B use -1, => only need to check abs value == n or not\n",
    "2. if find the full mark, the winning player must be the player who just made the move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.rows=[0]*n\n",
    "        self.cols=[0]*n\n",
    "        self.diagonal = 0\n",
    "        self.anti_diagonal = 0\n",
    "        self.n=n\n",
    "        \n",
    "    def move(self, row, col, player):\n",
    "        \"\"\"\n",
    "        Player {player} makes a move at ({row}, {col}).\n",
    "        @param row The row of the board.\n",
    "        @param col The column of the board.\n",
    "        @param player The player, can be either 1 or 2.\n",
    "        @return The current winning condition, can be either:\n",
    "                0: No one wins.\n",
    "                1: Player 1 wins.\n",
    "                2: Player 2 wins.\n",
    "        \"\"\"\n",
    "        val = 1 if player==1 else -1\n",
    "        self.rows[row]+=val\n",
    "        self.cols[col]+=val\n",
    "        if row == col:\n",
    "            self.diagonal+=val\n",
    "        if row+col == self.n-1:\n",
    "            self.anti_diagonal+=val\n",
    "        if abs(self.rows[row])==self.n or abs(self.cols[col])==self.n or abs(self.diagonal)==self.n or abs(self.anti_diagonal)==self.n:\n",
    "            return player\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a= TicTacToe(3)\n",
    "print(a.move(0,0,1))\n",
    "print(a.move(0,2,2))\n",
    "print(a.move(2,2,1))\n",
    "print(a.move(1,1,2))\n",
    "print(a.move(2,0,1))\n",
    "print(a.move(1,0,2))\n",
    "print(a.move(2,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 895. Maximun Frequency Stack </b>\n",
    "\n",
    "Composed of three elements in the stack:  a counter dictionary to track what number has what count; a default dictionary with list, to track what frequency has what number; a integer tracking what is the max frequency now.\n",
    "The genius step is the default dictionary with list for {freq: [num] }.  That means if x has freq n, x will appear in freq_stack[1], freq_stack[2], ... freq_stack[n]\n",
    "Max_freq integer is the key to know which number to pop out from defaultdict, how to update the max_freq based on the pop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "class FreqStack:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.freq = Counter()  # {num: count}\n",
    "        self.freq_stack = defaultdict(list)  # {freq: [num]}\n",
    "        self.max_f = 0 # max freq\n",
    "\n",
    "    def push(self, x: int) -> None:\n",
    "        self.freq[x] += 1\n",
    "        self.max_f = max(self.max_f, self.freq[x])\n",
    "        # genius step! if x has freq n, x will appear in freq_stack[1], freq_stack[2], ... freq_stack[n]\n",
    "        self.freq_stack[self.freq[x]].append(x) \n",
    "\n",
    "    def pop(self) -> int:\n",
    "        val = self.freq_stack[self.max_f].pop()\n",
    "        # if not empty, that means still have num with max_f as count\n",
    "        # if empty, max_f should be reduced. because max_f increases linearly, so -1 will brings to the next max freq\n",
    "        if not self.freq_stack[self.max_f]:\n",
    "            self.max_f -= 1\n",
    "        self.freq[val] -= 1\n",
    "        return val\n",
    "        \n",
    "\n",
    "\n",
    "# Your FreqStack object will be instantiated and called as such:\n",
    "# obj = FreqStack()\n",
    "# obj.push(x)\n",
    "# param_2 = obj.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n",
      "5\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "stack = FreqStack()\n",
    "stack.push(5)\n",
    "stack.push(7)\n",
    "stack.push(5)\n",
    "stack.push(7)\n",
    "stack.push(4)\n",
    "stack.push(5)  # => [5,7,5,7,4,5]\n",
    "print(stack.pop())\n",
    "print(stack.pop())\n",
    "print(stack.pop())\n",
    "print(stack.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 208. Implement Trie (Prefix Tree) </b>   \n",
    "\n",
    "Using a nested hash map structure to store the words, since words with same prefix are stored in a chain, it uses less space than storing all words directly in hash map, which when amount of words increase, the hash mapâ€™s collision rate will increase too.  \n",
    "The Trie structure is used in many scenarios, like autocomplete, spell checker, IP routing etc.\n",
    "M is the key length (the word length)  \n",
    "It supports insert(): O(M)  search(): O(M). Search prefix: O(M)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end = False # to check if the word is actually a word, or still half of a word\n",
    "\n",
    "class Trie:\n",
    "    \"\"\"imagine it as a tree, words with same prefix are coming out of same parent node\"\"\"\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "    def insert(self, word):\n",
    "        \"\"\"insert a word into the trie. loop each char to find the right place\"\"\"\n",
    "        current = self.root\n",
    "        for c in word:\n",
    "            if c not in current.children:\n",
    "                current.children[c]=TrieNode()  # nested hashmap \n",
    "            current = current.children[c]\n",
    "        current.is_end = True # mark the word is end, the node is the leaf node\n",
    "    \n",
    "    def search(self, word):\n",
    "        \"\"\"check if the word in the trie\"\"\"\n",
    "        current = self.root\n",
    "        for c in word:\n",
    "            if c not in current.children:\n",
    "                return False\n",
    "            current = current.children[c]\n",
    "        return current.is_end   # incase the word is actually half of another word\n",
    "    \n",
    "    def startsWith(self, prefix):\n",
    "        \"\"\"returns if any word in the trie that starts with prefix\"\"\"\n",
    "        current = self.root\n",
    "        for c in prefix:\n",
    "            if c not in current.children:\n",
    "                return False\n",
    "            current = current.children[c]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Your Trie object will be instantiated and called as such:\n",
    "obj = Trie()\n",
    "obj.insert(\"apple\")\n",
    "print(obj.search(\"apple\"))\n",
    "print(obj.startsWith(\"app\"))\n",
    "print(obj.search(\"app\"))\n",
    "obj.insert(\"app\")\n",
    "print(obj.search(\"app\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 211 Design Add and Search Words Data Structure </b>\n",
    "\n",
    "Using Trie structure.   \n",
    "in Search function, create a helper function as a recurisive helper to loop all possible routes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end = False\n",
    "        \n",
    "class WordDictionary:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()   # dont use __init__(self, root=TrieNode), the reference will cause problem\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        \"\"\"\n",
    "        Adds a word into the data structure.\n",
    "        \"\"\"\n",
    "        current = self.root\n",
    "        for c in word:\n",
    "            if c not in current.children:\n",
    "                current.children[c] = TrieNode()\n",
    "            current = current.children[c]\n",
    "        current.is_end = True\n",
    "    \n",
    "    def search(self, word):\n",
    "        \n",
    "        def helper_search(word, node):\n",
    "            for i, c in enumerate(word):\n",
    "                if c not in node.children:\n",
    "                    if c == '.':\n",
    "                        for next_node in node.children.values():\n",
    "                            if helper_search(word[i+1:], next_node):\n",
    "                                return True\n",
    "                    return False\n",
    "                else:\n",
    "                    node = node.children[c]\n",
    "            return node.is_end\n",
    "        \n",
    "        return helper_search(word, self.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Your WordDictionary object will be instantiated and called as such:\n",
    "obj = WordDictionary()\n",
    "print(obj.search(\"a\"))\n",
    "obj.addWord(\"word\")\n",
    "print(obj.search(\"wor\"))\n",
    "print(obj.search(\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 212. Word Search II </b>\n",
    "\n",
    "Trie plus Backtacking recursion. a very smart solution.  \n",
    "the list of words needed to be searched is used to construct the trie.  \n",
    "backtracking run through the whole board in 4 directions to compare with the trie node.\n",
    "\n",
    "in the Trie structure, is_end can be replaced by other attributes, like here self.word, which stores the entire target word in the words list, marking a word is found, making it easier to know what the word is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        # self.is_end = False\n",
    "        self.word = False   # save the actual complete word at the end of the word char\n",
    "        \n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "        \n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for c in word:\n",
    "            if c not in node.children:\n",
    "                node.children[c] = TrieNode()\n",
    "            node = node.children[c]\n",
    "        node.word = word   # marking the end of the word, also save the entire word here for future usage\n",
    "\n",
    "class Solution:\n",
    "    def findWords(self, board, words):\n",
    "        \"\"\"trie structure and backtracking\n",
    "        making a trie for the words list, NOT the board\n",
    "        backtracking the board to exhaust every possible direciton, like the island question\n",
    "        \"\"\"\n",
    "        if (len(board)==0) or len(board[0])==0:\n",
    "            return []\n",
    "        trie = Trie()\n",
    "        node = trie.root\n",
    "        res = []\n",
    "        \n",
    "        for w in words:\n",
    "            trie.insert(w)\n",
    "        \n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[0])):\n",
    "                self.dfs_helper(board, i, j, node, res)\n",
    "        return res\n",
    "    \n",
    "    def dfs_helper(self, board, i, j, node, res):\n",
    "        \"\"\"backtracking\"\"\"\n",
    "        \n",
    "        # base case 1: find the word\n",
    "        if node.word:\n",
    "            res.append(node.word)\n",
    "            node.word = False # avoid duplicates\n",
    "            # dont return here because this node may have children which mark other words\n",
    "            \n",
    "        # base case 2: i, j are out of bound\n",
    "        if i<0 or j<0 or i>=len(board) or j>=len(board[0]):\n",
    "            return\n",
    "        \n",
    "        # normal case\n",
    "        c = board[i][j]\n",
    "        node = node.children.get(c)\n",
    "        if not node:\n",
    "            # [i][j] is not the right path\n",
    "            return\n",
    "        \n",
    "        # c is the next char, continue\n",
    "        board[i][j] = '#'\n",
    "        # node now is a new node\n",
    "        self.dfs_helper(board, i+1, j, node, res)\n",
    "        self.dfs_helper(board, i-1, j, node, res)\n",
    "        self.dfs_helper(board, i, j+1, node, res)\n",
    "        self.dfs_helper(board, i, j-1, node, res)\n",
    "        # hey backtracking pattern\n",
    "        board[i][j] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oath', 'eat']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = [['o','a','a','n'],\n",
    "  ['e','t','a','e'],\n",
    "  ['i','h','k','r'],\n",
    "  ['i','f','l','v']]\n",
    "words = [\"oath\",\"pea\",\"eat\",\"rain\"]\n",
    "word_search = Solution()\n",
    "word_search.findWords(board, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 642. Design Search Autocomplete System </b>\n",
    "\n",
    "Trie structure, each branch represents a sentence. each node is a character, including empty space as valid char.  \n",
    "dfs recursion is used to find all possible sentences with same prefix phrase.    \n",
    "sorted by ranking to give the proper recommendations  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        # self.is_end = False\n",
    "        self.sent = None\n",
    "        self.rank = 0\n",
    "        \n",
    "class AutocompleteSystem:\n",
    "    \"\"\" implement a Trie inside of this system\n",
    "        The Trie's children is still char, the branch of Trie is a sentence, including space as valid char\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, times):\n",
    "        self.root = TrieNode()\n",
    "        self.keyword = \"\"  # used to save what has typed before sent ended\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            self.add_record(sentence, times[i])\n",
    "        \n",
    "    def add_record(self, sentence, hot_degree):\n",
    "        node = self.root\n",
    "        for c in sentence:   # loop each char in the sentence\n",
    "            if c not in node.children:\n",
    "                node.children[c] = TrieNode()\n",
    "            node = node.children[c]\n",
    "        # at the end of the sentence\n",
    "        node.sent = sentence\n",
    "        node.rank -= hot_degree\n",
    "    \n",
    "    def search(self, phrase):\n",
    "        \"\"\"return historical sents with phrase as prefix\n",
    "            return a list of sentences\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        for c in phrase:\n",
    "            if c not in node.children:\n",
    "                return []\n",
    "            node = node.children[c]\n",
    "        # now the node is representing the end of the phrase\n",
    "        # in Trie, this node can have many sub branch \n",
    "        return self.dfs_helper(node)\n",
    "    \n",
    "    def dfs_helper(self, node):\n",
    "        \"\"\"return a list of sentences\"\"\"\n",
    "        res = []\n",
    "        if node:\n",
    "            if node.sent:\n",
    "                # node happens to be the end of a complete sentence\n",
    "                res.append((node.rank, node.sent))\n",
    "            \n",
    "            # NOTE HERE: even though node is not the end of sentence, still need to recursively check its children    \n",
    "            for next_node in node.children.values():\n",
    "                res.extend(self.dfs_helper(next_node))\n",
    "        return res\n",
    "        \n",
    "\n",
    "    def input(self, c):\n",
    "        result = []\n",
    "        if c!= '#':\n",
    "            # sentence not complete yet\n",
    "            self.keyword += c\n",
    "            # search the Trie against the so far typed words\n",
    "            result = self.search(self.keyword)\n",
    "        else:\n",
    "            # sentence ended, add this new sentence to the Trie\n",
    "            self.add_record(self.keyword, 1)\n",
    "            self.keyword = \"\"\n",
    "        return [item[1] for item in sorted(result)[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5, 'i love you'), (-2, 'i love leetcode'), (-3, 'island'), (-2, 'iroman')]\n",
      "['i love you', 'island', 'i love leetcode']\n",
      "[(-5, 'i love you'), (-2, 'i love leetcode')]\n",
      "['i love you', 'i love leetcode']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "auto = AutocompleteSystem([\"i love you\",\"island\",\"iroman\",\"i love leetcode\"],[5,3,2,2])\n",
    "print(auto.input(\"i\"))\n",
    "print(auto.input(\" \"))\n",
    "print(auto.input(\"a\"))\n",
    "print(auto.input(\"#\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 380. Insert Delete GetRandom O(1) </b>\n",
    "\n",
    "the problem wants to solve insert, delete, and get random three actions all in O(1) time.  \n",
    "for get random in O(1), The idea is to choose a random index and then to retrieve an element with that index. So there should be a list. For insert and find if element exist or not, a hashmap would be O(1).    \n",
    "=> in this way the data structures need a list and a hashmap.\n",
    "\n",
    "using the list ot save the actual value, using hashmap to store the val => index pair, while having the index, you can retrieve the value from the list in O(1).   \n",
    "\n",
    "the delete part is smart, using the last element of the list to replace the target value, then pop the last value from the list, and remove the record of target value from the hashmap, then update the last element's index in the hashmap too. Every step is O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class RandomizedSet:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.data_list = []  # save the actual value\n",
    "        self.val_ind_map = {} # value => index in the list\n",
    "        \n",
    "\n",
    "    def insert(self, val: int) -> bool:\n",
    "        \"\"\"\n",
    "        Inserts a value to the set. Returns true if the set did not already contain the specified element.\n",
    "        \"\"\"\n",
    "        if val not in self.val_ind_map:\n",
    "            ind = len(self.data_list)\n",
    "            self.val_ind_map[val] = ind\n",
    "            self.data_list.append(val)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def remove(self, val: int) -> bool:\n",
    "        \"\"\"\n",
    "        Removes a value from the set. Returns true if the set contained the specified element.\n",
    "        \"\"\"\n",
    "        # smart way of removing the element in O(1)\n",
    "        if val in self.val_ind_map:\n",
    "            ind = self.val_ind_map[val]\n",
    "            last_val = self.data_list[-1]\n",
    "            # replace val's position with the last_val, and pop the last_val\n",
    "            self.data_list[ind] = last_val # O(1)\n",
    "            self.val_ind_map[last_val] = ind # O(1)\n",
    "            self.data_list.pop()  # O(1)\n",
    "            del self.val_ind_map[val] #O(1)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    def getRandom(self) -> int:\n",
    "        \"\"\"\n",
    "        Get a random element from the set.\n",
    "        \"\"\"\n",
    "        return random.choice(self.data_list)\n",
    "        \n",
    "\n",
    "\n",
    "# Your RandomizedSet object will be instantiated and called as such:\n",
    "# obj = RandomizedSet()\n",
    "# param_1 = obj.insert(val)\n",
    "# param_2 = obj.remove(val)\n",
    "# param_3 = obj.getRandom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 981 Time Based Key-Value Store </b>\n",
    "\n",
    "way 1: hashmap + heapqueue, letting heapqueue to do the binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "class TimeMap:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.hash_map=defaultdict(list) # save {key: heapq(timestamp, val)}\n",
    "        \n",
    "\n",
    "    def set(self, key: str, value: str, timestamp: int) -> None:\n",
    "        heapq.heappush(self.hash_map[key], (timestamp, value)) \n",
    "\n",
    "    def get(self, key: str, timestamp: int) -> str:\n",
    "        if key not in self.hash_map:\n",
    "            return \"\"\n",
    "        queue = self.hash_map[key]\n",
    "        for i in range(len(queue)-1, -1, -1):\n",
    "            t, v = queue[i]\n",
    "            if t<=timestamp:\n",
    "                return v\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "way 2: hash_map + binary search,  since the timestamp added is in order, so able to use the binary search. => but it is slower\n",
    "\n",
    "i tried l<=r, but does not work well. suppose when l<=r, still enter the while loop, either l=m+1, or r=m-1 then while loop end. now not sure the right index is l-1 or r+1, need two checks. But using l < r at this case can avoid the check. when the while loop stop, the l == r, at position r, the value is not <= timestamp, the m in l = m+1 points to the right time stamp, so r-1, or l-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "class TimeMap:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.hash_map=defaultdict(list) # save {key: [(timestamp, val)]}\n",
    "        \n",
    "\n",
    "    def set(self, key: str, value: str, timestamp: int) -> None:\n",
    "        self.hash_map[key].append((timestamp, value)) \n",
    "\n",
    "    def get(self, key: str, timestamp: int) -> str:\n",
    "        if key not in self.hash_map:\n",
    "            return \"\"\n",
    "        queue = self.hash_map[key]\n",
    "        l = 0\n",
    "        r = len(queue) # l and r is the range of index\n",
    "        while l < r:  \n",
    "            m = l+(r-l)//2\n",
    "            if queue[m][0]<=timestamp:\n",
    "                l=m+1\n",
    "            else:\n",
    "                r=m\n",
    "\n",
    "        return \"\" if r == 0 else queue[r-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 706 design hashmap </b>  \n",
    "\n",
    "Using a list and a liked list to accomplish the functionality of hashmap instead of using the built-in hashmap structure  \n",
    "\n",
    "Initialize a list with size 1000, why 1000? because the key and values are in range [0, 1000000], a list with size 1000 is enough to hold all linked list, on average each splot in the list will hold a linked list with length of 1000  so x % 1000 will always fall into the range of [0, 999] which has length 1000. Linked list is used to address collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikedList:\n",
    "    def __init__(self, k, v):\n",
    "        self.key = k\n",
    "        self.val = v\n",
    "        self.next = None\n",
    "        \n",
    "class MyHashMap:\n",
    "    \"\"\"using a list and linked list to represent the hashmap structure\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        # because the key and values are in range [0, 1000000], a list with size 1000 is enough to hold all linked list, on average each splot in the list will hold a linked list with length of 1000\n",
    "        self.size =  1000 \n",
    "        self.hash_map = [None]*self.size\n",
    "\n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        \"\"\"\n",
    "        value will always be non-negative.\n",
    "        \"\"\"\n",
    "        hash_key = key % self.size\n",
    "        if self.hash_map[hash_key] is None:\n",
    "            self.hash_map[hash_key] = LikedList(key, value)\n",
    "        else:\n",
    "            cur_node = self.hash_map[hash_key]\n",
    "            while True:\n",
    "                # update value if the key exists\n",
    "                if cur_node.key == key:\n",
    "                    cur_node.val = value\n",
    "                    return\n",
    "                # otherwise add a new node in the right position\n",
    "                if cur_node.next is None:\n",
    "                    break\n",
    "                else:\n",
    "                    cur_node = cur_node.next\n",
    "            cur_node.next = LikedList(key, value)\n",
    "        \n",
    "    def get(self, key: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key\n",
    "        \"\"\"\n",
    "        hash_key = key % self.size\n",
    "        cur_node = self.hash_map[hash_key]\n",
    "        while cur_node is not None:\n",
    "            if cur_node.key == key:\n",
    "                return cur_node.val\n",
    "            else:\n",
    "                cur_node = cur_node.next\n",
    "        return -1\n",
    "        \n",
    "\n",
    "    def remove(self, key: int) -> None:\n",
    "        \"\"\"\n",
    "        Removes the mapping of the specified value key if this map contains a mapping for the key\n",
    "        \"\"\"\n",
    "        hash_key = key % self.size\n",
    "        cur_node = pre_node = self.hash_map[hash_key]\n",
    "        # unlink the linked node\n",
    "        if cur_node is None: return\n",
    "        if cur_node.key == key:\n",
    "            # important, cant use pre_node.next = cur_node.next, the connection wont work\n",
    "            self.hash_map[hash_key] = cur_node.next\n",
    "        else:\n",
    "            cur_node = cur_node.next # now pre_node and cur_node are pointing to adjacent nodes\n",
    "            while cur_node:\n",
    "                if cur_node.key == key:\n",
    "                    pre_node.next = cur_node.next\n",
    "                    return\n",
    "                else:\n",
    "                    cur_node = cur_node.next\n",
    "                    pre_node = pre_node.next\n",
    "        \n",
    "\n",
    "\n",
    "# Your MyHashMap object will be instantiated and called as such:\n",
    "# obj = MyHashMap()\n",
    "# obj.put(key,value)\n",
    "# param_2 = obj.get(key)\n",
    "# obj.remove(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "obj = MyHashMap()\n",
    "obj.put(2,2)\n",
    "print(obj.get(2))\n",
    "obj.put(2,1)\n",
    "print(obj.get(2))\n",
    "obj.remove(2)\n",
    "print(obj.get(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 341 flatten nested list iterator </b>\n",
    "\n",
    "hasNext do the recursive part until the first element of the stack is flatten into a normal integer\n",
    "Next() directly pop and return the first flattened item\n",
    "\n",
    "cons of this solution: pop(0) from a stack takes O(N), slower than pop(), also everytime the hasNext() function makes a copy of the stack O(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This is the interface that allows for creating nested lists.\n",
    "# You should not implement it, or speculate about its implementation\n",
    "# \"\"\"\n",
    "# class NestedInteger:\n",
    "#     def isInteger(self) -> bool:\n",
    "#        \"\"\"\n",
    "#        @return True if this NestedInteger holds a single integer, rather than a nested list.\n",
    "#        \"\"\"\n",
    "\n",
    "#     def getInteger(self) -> int:\n",
    "#        \"\"\"\n",
    "#        @return the single integer that this NestedInteger holds, if it holds a single integer\n",
    "#        Return None if this NestedInteger holds a nested list\n",
    "#        \"\"\"\n",
    "\n",
    "#     def getList(self) -> [NestedInteger]:\n",
    "#        \"\"\"\n",
    "#        @return the nested list that this NestedInteger holds, if it holds a nested list\n",
    "#        Return None if this NestedInteger holds a single integer\n",
    "#        \"\"\"\n",
    "\n",
    "class NestedIterator:\n",
    "    def __init__(self, nestedList):\n",
    "        # nestedList: [NestedInteger]\n",
    "        self.stack = nestedList\n",
    "    \n",
    "    def next(self) -> int:\n",
    "        return self.stack.pop(0).getInteger()\n",
    "    \n",
    "    def hasNext(self) -> bool:\n",
    "        \"\"\"recursive until first element in the stack is not a list\"\"\"\n",
    "        while self.stack:\n",
    "            top = self.stack[0]\n",
    "            if top.isInteger():\n",
    "                return True\n",
    "            else:\n",
    "                self.stack = top.getList()+self.stack[1:]\n",
    "        return False\n",
    "\n",
    "         \n",
    "\n",
    "# Your NestedIterator object will be instantiated and called as such:\n",
    "# i, v = NestedIterator(nestedList), []\n",
    "# while i.hasNext(): v.append(i.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 173 Binary Search Tree Iterator </b>\n",
    "\n",
    "way 1: hack it by iterating the tree in-order and save the result to a stack  \n",
    "wah 2: others way, smart to use the stack, preorder adding the stack, then the last item in the stack is actually the lower left item in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TreeNode:\n",
    "#     def __init__(self, val=0, left=None, right=None):\n",
    "#         self.val = val\n",
    "#         self.left = left\n",
    "#         self.right = right\n",
    "class BSTIterator:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        # root: TreeNode\n",
    "        self.stack=[]\n",
    "        self.push_node(root)\n",
    "        \n",
    "\n",
    "    def next(self) -> int:\n",
    "        \"\"\"\n",
    "        @return the next smallest number\n",
    "        \"\"\"\n",
    "        if not self.stack:\n",
    "            return\n",
    "        node = self.stack.pop() # the last node in the stack is the left most node in the tree\n",
    "        self.push_node(node.right) # smart, now the last node in the stack is still the smallest item\n",
    "        return node.val\n",
    "        \n",
    "\n",
    "    def hasNext(self) -> bool:\n",
    "        \"\"\"\n",
    "        @return whether we have a next smallest number\n",
    "        \"\"\"\n",
    "        return len(self.stack) > 0\n",
    "    \n",
    "    def push_node(self, node):\n",
    "        while node:\n",
    "            self.stack.append(node)\n",
    "            node = node.left  \n",
    "            # now the stack has [root,xxx, left lower most item]\n",
    "    \n",
    "\n",
    "# Your BSTIterator object will be instantiated and called as such:\n",
    "# obj = BSTIterator(root)\n",
    "# param_1 = obj.next()\n",
    "# param_2 = obj.hasNext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1396 design underground system </b>\n",
    "\n",
    "check the accepted one vs the previous failed one. The accepted one is able to accumulate info over checkout step, so when calculating avg time, it can grab the related info immediately, instead of calculating the sum and count again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndergroundSystem:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start = {} # {id: (station, t)}\n",
    "        self.stack = {} # {(start, end): (count, sum of interval)}\n",
    "\n",
    "    def checkIn(self, id: int, stationName: str, t: int) -> None:\n",
    "        # assume very input is valid, wont have cases like same id checkins in at different station before any checkout\n",
    "        self.start[id] = (stationName, t)\n",
    "\n",
    "    def checkOut(self, id: int, stationName: str, t: int) -> None:\n",
    "        start_station, start_t = self.start[id]\n",
    "        if (start_station, stationName) not in self.stack:\n",
    "            self.stack[(start_station, stationName)] = (1, t-start_t)\n",
    "        else:\n",
    "            prev_count, prev_sum_t = self.stack[(start_station, stationName)]\n",
    "            self.stack[(start_station, stationName)] = (prev_count+1, prev_sum_t+(t-start_t))\n",
    "\n",
    "    def getAverageTime(self, startStation: str, endStation: str) -> float:\n",
    "        count, sum_time = self.stack[(startStation, endStation)]\n",
    "        return sum_time/count\n",
    "\n",
    "# Your UndergroundSystem object will be instantiated and called as such:\n",
    "# obj = UndergroundSystem()\n",
    "# obj.checkIn(id,stationName,t)\n",
    "# obj.checkOut(id,stationName,t)\n",
    "# param_3 = obj.getAverageTime(startStation,endStation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 460 LFU cache </b>  \n",
    "Least frequently used cache, it utilizes the Least Recently Used Cache problemâ€™s solution\n",
    "Having 2 class attributes: one is a dictionary, storing {key: frequency} pair, another is a dictionary store {frequency: {key: value} } the {key: value} inside of it is a OrderedDict object, which is the LRU solution to address the tie situation in the LFU problem.  \n",
    "Besides the two dictionary, keep the min_f attribute to store the min frequency so far, used to quickly allocate what to delete if the size exceeds the capacity.  \n",
    "In get method, if the key exists, need to increase the frequency by 1, and remove the current key value pair for its current frequency. Pay attention to the case where the frequency happens to be the min freq of the class and now it is emptied, which means the min_f of the class needs to update by adding 1.  \n",
    "In the put method, need to take care of the edge cases where the capacity is <=0. If key already exist, need to update the frequency, same as the put method.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "class LFUCache:\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.min_f = -1\n",
    "        self.store = {} # store {key: freq} pair\n",
    "        # ordereddict can be a double linked list\n",
    "        self.freq_key = defaultdict(OrderedDict) # {freq: {key: value}}\n",
    "\n",
    "    def get(self, key: int) -> int:\n",
    "        if key not in self.store:\n",
    "            return -1\n",
    "        else:\n",
    "            freq = self.store[key]\n",
    "            val = self.freq_key[freq][key]\n",
    "            # update the frequency and order\n",
    "            self.store[key] = freq + 1\n",
    "            del self.freq_key[freq][key]\n",
    "            if freq == self.min_f and len(self.freq_key[freq])==0:\n",
    "                # this freq's value has been emptyed\n",
    "                self.min_f+=1\n",
    "            self.freq_key[freq+1][key] = val\n",
    "            \n",
    "            return val\n",
    "\n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        # edge cases!\n",
    "        if self.capacity <= 0:\n",
    "            return\n",
    "        if key in self.store: # no need to worry about capacity\n",
    "            freq = self.store[key]\n",
    "            self.freq_key[freq][key] = value\n",
    "            # udpate frequency\n",
    "            self.get(key)\n",
    "            \n",
    "            return\n",
    "        \n",
    "        # invalidate the least freq item before inserting new item\n",
    "        if len(self.store) >= self.capacity:\n",
    "            k_v_dict = self.freq_key[self.min_f]\n",
    "            if len(k_v_dict) > 0:\n",
    "                k, v = k_v_dict.popitem(last=False) # ensure LILO\n",
    "                del self.store[k]\n",
    "            # no need to update the min_f here because it will be set as 1 in the next step\n",
    "#             if len(k_v_dict) == 0:\n",
    "#                 self.min_f += 1            \n",
    "        # otherwise adding a new item to the store, min freq would be 1 for the new item\n",
    "        self.min_f = 1\n",
    "        self.store[key] = 1\n",
    "        self.freq_key[1][key] = value\n",
    "        \n",
    "\n",
    "\n",
    "# Your LFUCache object will be instantiated and called as such:\n",
    "# obj = LFUCache(capacity)\n",
    "# param_1 = obj.get(key)\n",
    "# obj.put(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testground",
   "language": "python",
   "name": "testground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
