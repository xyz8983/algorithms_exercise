{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs!  \n",
    "\n",
    "actually similar to trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 127. Word Ladder </b>\n",
    "\n",
    "only change from word to words that have exactly one letter difference. in this way the problem can be transformed into a graph problem, begin word => visit its neighbors (defined as word with only one char difference) => non-visited neighbors' neighbors => until we arrived at the end word.\n",
    "\n",
    "so it is a breath first search structure. (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Solution:\n",
    "    def ladderLength(self, beginWord, endWord, wordList):\n",
    "        def construct_neighbors(word_list):\n",
    "            d = {}\n",
    "            for word in word_list:\n",
    "                for i in range(len(word)):\n",
    "                    # no need to worry i+1 is out of bound, cz slicing wont give index out of bound error\n",
    "                    key = word[:i]+'_'+word[i+1:]\n",
    "                    d[key] = d.get(key, [])+[word]  # {'_ot': ['lot', 'dot', 'hot']}\n",
    "            return d\n",
    "        \n",
    "        def bfs_words(begin, end, word_dict):\n",
    "            # queue has word and level => step\n",
    "            # why initiate the step as 1? => example \"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> \"cog\", result should be 5, not 4\n",
    "            queue, visited = deque([(begin, 1)]), set()\n",
    "            while queue:\n",
    "                word, step = queue.popleft()  # this is why using deque\n",
    "                if word not in visited:  # this check makes the execution much much faster\n",
    "                    visited.add(word)\n",
    "                    if word == end:\n",
    "                        return step\n",
    "                    # otherwise find its neighbors and add to queue\n",
    "                    for i in range(len(word)):\n",
    "                        s = word[:i] + '_' + word[i+1:]\n",
    "                        neighbors = word_dict.get(s, [])\n",
    "                        for n_word in neighbors:\n",
    "                            if n_word not in visited:\n",
    "                                queue.append((n_word, step+1))\n",
    "            return 0\n",
    "        \n",
    "        if endWord not in wordList:\n",
    "            return 0\n",
    "        word_dict = construct_neighbors(set(wordList))\n",
    "        return bfs_words(beginWord, endWord, word_dict)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "word_dict = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "a= Solution()\n",
    "a.ladderLength(beginWord, endWord, word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bidirectional BFS. Search both from start word and end word, if they meet at some intermediate word, that means existing such a road from start word to end word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, defaultdict\n",
    "class Solution:\n",
    "    def ladderLength(self, beginWord, endWord, wordList):\n",
    "        \"\"\"bidirectional BFS\"\"\"\n",
    "        \n",
    "        def find_words(queue, one_visited, two_visited):\n",
    "            \"\"\"\n",
    "            queue: [(word, level)], deque\n",
    "            one_visited: {word: level} current direction\n",
    "            two_visited; {word: level} the other direction\n",
    "            \"\"\"\n",
    "            word, step = queue.popleft()\n",
    "            for i in range(L):\n",
    "                intermediate = word[:i]+'_'+word[i+1:]\n",
    "                \n",
    "                for neighbor in neighbors_dict[intermediate]:\n",
    "                    if neighbor in two_visited:\n",
    "                        return step + two_visited[neighbor]\n",
    "                    if neighbor not in one_visited:\n",
    "                        one_visited[neighbor] = step + 1\n",
    "                        queue.append((neighbor, step+1))\n",
    "            return\n",
    "        \n",
    "        if endWord not in wordList:\n",
    "            return 0\n",
    "        \n",
    "        L = len(beginWord)\n",
    "        \n",
    "        # construct neighbors dictionary\n",
    "        neighbors_dict = defaultdict(list)\n",
    "        for word in wordList:\n",
    "            for i in range(L):  # only need to loop L time\n",
    "                key = word[:i]+'_'+word[i+1:]\n",
    "                neighbors_dict[key].append(word)\n",
    "        \n",
    "        queue_begin = deque([(beginWord, 1)])\n",
    "        queue_end = deque([(endWord, 1)])\n",
    "        visited_begin = {beginWord: 1}\n",
    "        visited_end = {endWord: 1}\n",
    "        # if one queue is empty the other is not, but they still dont meet, that means no such a way\n",
    "        while queue_begin and queue_end:\n",
    "            # queue_begin, queue_end, visited_begin, visited_end are all reference and are updated in side of the\n",
    "            # execution of find_words() method\n",
    "            # go forward one level from begin word\n",
    "            res = find_words(queue_begin, visited_begin, visited_end)\n",
    "            if res:\n",
    "                return res\n",
    "            # go forward one level from end word\n",
    "            res = find_words(queue_end, visited_end, visited_begin)\n",
    "            if res:\n",
    "                return res\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "b= Solution()\n",
    "b.ladderLength(beginWord, endWord, wordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 126 Word Ladder II </b>\n",
    "\n",
    "still can create a graph,   \n",
    "one layer over one layer, each layer is a dictionary, key as valid word, value as all possible path whose last value is this valid word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def findLadders(beginWord, endWord, wordList):\n",
    "    def construct_graph(wordList, beginWord):\n",
    "        l = len(beginWord)\n",
    "        d = {}\n",
    "        for word in wordList:\n",
    "            for i in range(l):\n",
    "                key = word[:i] + '_' + word[i+1:]\n",
    "                d[key] = d.get(key, [])+[word]\n",
    "        return d\n",
    "    \n",
    "    if endWord not in wordList:\n",
    "        return []\n",
    "    \n",
    "    result = []\n",
    "    word_graph = construct_graph(wordList, beginWord)\n",
    "    wordList = set(wordList)  # set searching is O(1)\n",
    "    layer = {} # as the queue\n",
    "    # key: last word in the path, value: list of list of words, each list of words's last word is the key\n",
    "    layer[beginWord] = [[beginWord]] # a list of possible path end up in beginWord\n",
    "    while layer:\n",
    "        next_layer = defaultdict(list)\n",
    "        for word in layer:\n",
    "            if word == endWord:\n",
    "#                 result.extend(path for path in layer[word])\n",
    "                result.extend(layer[word])\n",
    "            else:\n",
    "                # searching neighbors\n",
    "                for i in range(len(word)):\n",
    "                    key = word[:i] + '_' + word[i+1:]\n",
    "                    neighbors = word_graph.get(key, [])\n",
    "                    for w in neighbors:\n",
    "                        if w in wordList:\n",
    "                            next_layer[w]+=[path+[w] for path in layer[word]]\n",
    "        wordList -= set(next_layer.keys())  # remove visited node => replace it with visited set is okay too\n",
    "        layer=next_layer\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "findLadders(beginWord, endWord, wordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 207 Course Schedule </b>\n",
    "\n",
    "the problem is also known as topological sort problem, which is to find a global order for all nodes in a DAG (Directed Acyclic Graph) with regarding to their dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Topological sort </b>  \n",
    "construct a graph:{prerequisite: [dependings]}  \n",
    "construct a degree dictionary: {course: degree integer}: n degree means this course has n prerequisits need to take  \n",
    "the course with degree 0 is the one able to take first. if no course has 0 degree, the courses are in a loop, cant be finished.\n",
    "first starting with courses with degree 0, find its depending courses and reduce their degrees by 1. that means number of requisites needs to be finished before able to take the depending course is reduced by 1. If now a new course has degree 0, add it to the start course queue.  \n",
    "at the end if all courses are taken, each of the degree is 0, sum is 0 too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "def canFinish(numCourses, prerequisites):\n",
    "    # construct a graph:{prerequisite: [dependings]}\n",
    "    graph = defaultdict(list)\n",
    "    # construct a degree dictionary: {course: degree integer}\n",
    "    # n degree means this course has n prerequisits need to take\n",
    "    degree = [0]*numCourses\n",
    "    for d, pre in prerequisites:\n",
    "        graph[pre].append(d)\n",
    "        degree[d]+=1 # course number happens to be used as index\n",
    "\n",
    "    # the course with degree 0 is the able to take first. if no course has 0 degree, the courses are in a loop, cant be finished\n",
    "    start_courses = deque([i for i in range(numCourses) if degree[i]==0])\n",
    "    while start_courses:\n",
    "        pre = start_courses.popleft()\n",
    "        for j in graph[pre]:\n",
    "            # j is the depending courses of i\n",
    "            degree[j]-=1  # number of requisites needs to be finished before able to take the course j is reduced by 1\n",
    "            if degree[j]==0:\n",
    "                # able to take it as next course\n",
    "                start_courses.append(j)\n",
    "    # if all courses are taken, they will all be 0\n",
    "    return not sum(degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numCourses = 2\n",
    "prerequisites = [[1,0],[0,1]]\n",
    "canFinish(numCourses, prerequisites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 210 course schedule II </b>.   \n",
    "similar as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "def findOrder(numCourses, prerequisites): \n",
    "    graph = defaultdict(list)  # {prerequisite: [depending courses]}\n",
    "    degree=[0]*numCourses  # [integer] how many prerequisites needs to take\n",
    "\n",
    "    for course, pre in prerequisites:\n",
    "        graph[pre].append(course)\n",
    "        degree[course]+=1 \n",
    "\n",
    "    result=[]\n",
    "    # start with course with no prerequisite\n",
    "    starting_course = deque([i for i in range(numCourses) if degree[i]==0])\n",
    "    while starting_course:\n",
    "        course = starting_course.popleft()\n",
    "        result.append(course)\n",
    "        # its dependencies' degree - 1\n",
    "        for d in graph[course]:\n",
    "            degree[d]-=1\n",
    "            if degree[d]==0:  # this also helps avoid class that is already taken\n",
    "                # able to be taken next\n",
    "                starting_course.append(d)\n",
    "\n",
    "    if sum(degree)==0:\n",
    "        # all courses are taken\n",
    "        return result\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numCourses = 4\n",
    "prerequisites=[[1,0],[2,0],[3,1],[3,2]]\n",
    "findOrder(numCourses, prerequisites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 399 evaluate division </b>\n",
    "\n",
    "YEAH! I DID IT!  \n",
    "it is a directed graph problem, using breath first search to search target value layer by layer (neighbor by neighbor), remember to skip the visited node to avoid endless loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def calcEquation(equations, values, queries):\n",
    "    result = [-1.0]*len(queries)\n",
    "    # construct the graph\n",
    "    graph = defaultdict(dict)\n",
    "    # looks like {a: {b, 2}, b:{a: 1/2, c: 3}, c:{b:1/3}}\n",
    "    for ind, (i, j) in enumerate(equations):\n",
    "        graph[i][j]= values[ind]\n",
    "        graph[j][i]= 1/values[ind]\n",
    "\n",
    "    def helper(x, y):\n",
    "        # BFS helper function,find path from x to y, given a graph\n",
    "        queue = [(x,1)] # (node, val)\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            node, val = queue.pop()\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "            neighbors = graph[node] # a dict {node:value}\n",
    "            if y in neighbors:\n",
    "                return val*neighbors[y]\n",
    "            else:\n",
    "                for n in neighbors:\n",
    "                    queue.append((n, val*neighbors[n]))\n",
    "            # queue = next_queue\n",
    "        return -1.0\n",
    "\n",
    "    for ind, (x, y) in enumerate(queries):\n",
    "        if x not in graph or y not in graph:\n",
    "            continue\n",
    "        elif x==y and x in graph[x]:\n",
    "            result[ind] = 1.0\n",
    "        elif y in graph[x]:\n",
    "            result[ind] = graph[x][y]\n",
    "        else:\n",
    "            # find the transition path\n",
    "            # there maybe multiple paths, but since the assumption is there is no contradiction, it is safe to pick random one\n",
    "            # depth first search, search neighbors and neighbors' neighbors until get the target\n",
    "\n",
    "            result[ind] = helper(x, y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0, 0.5, -1.0, 1.0, -1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equations = [ [\"a\", \"b\"], [\"b\", \"c\"] ]\n",
    "values = [2.0, 3.0]\n",
    "queries = [ [\"a\", \"c\"], [\"b\", \"a\"], [\"a\", \"e\"], [\"a\", \"a\"], [\"x\", \"x\"]] \n",
    "calcEquation(equations, values, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 947 most stones removed with same row or column </b>\n",
    "\n",
    "the question is actually finding the number of islands, which are defined as nodes share same row or column. that is if two nodes are common in row or column value, they are in the same island.  \n",
    "two ways are used here.   \n",
    "=> Union Find, a new structure  \n",
    "=> DFS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>way 1</b> union find. not too sure how it works still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStones(stones):\n",
    "    \"\"\"union find\"\"\"\n",
    "    \"\"\"\n",
    "    Connected stones can be reduced to 1 stone,\n",
    "    the maximum stones can be removed = stones number - islands number.\n",
    "    Two stones are connected if they are in the same row or same col.\n",
    "    \"\"\"\n",
    "    UF = {}\n",
    "    def find(x):\n",
    "        if x!=UF[x]:\n",
    "            UF[x] = find(UF[x])\n",
    "        return UF[x]\n",
    "\n",
    "    def union(x, y):\n",
    "        UF.setdefault(x,x)\n",
    "        UF.setdefault(y,y)\n",
    "        UF[find(x)] = find(y)\n",
    "\n",
    "\n",
    "    for i, j in stones:\n",
    "        # need to separate j from i to distinct range, so they can be key\n",
    "        union(i, ~j)\n",
    "        # here ~j will make the range for j to [-1, -10001]\n",
    "    # for element in UF, find its root, the number of unique root is the number of set\n",
    "    return len(stones) - len({find(x) for x in UF})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> way 2</b> DFS way, easier to understand\n",
    "\n",
    "first constructing the \"graph\" structure, which is two dict of list, representing rows (rows: [cols share the same rows]) and cols(col: [rows share the same col]).   \n",
    "then a dfs helper function to discard the point out, and loop through each of the neighbors(points share same row or col). keep track of the island number.  \n",
    "because each island can only left 1 stone, so the max number of stone can be removed is total stone number - island number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def removeStones(stones):\n",
    "    \"\"\"finding the number of island, then stone number - island number is the largest stone you can remove, so that means each island finally got 1 stone\"\"\"\n",
    "\n",
    "    def dfs_helper(i, j):\n",
    "        \"\"\"discard points with same row or col, recursive to loop all points in the same island\"\"\"\n",
    "        points.discard((i, j))  # discard() method wont raise error if node not exist\n",
    "        # go along the neighbor\n",
    "        for y in rows[i]:\n",
    "            if (i, y) in points:\n",
    "                dfs_helper(i, y)\n",
    "        for x in cols[j]:\n",
    "            if (x, j) in points:\n",
    "                dfs_helper(x, j)\n",
    "\n",
    "    # points is a set! and will be modified in the dfs helper\n",
    "    points = {(i, j) for i, j in stones}\n",
    "    island = 0\n",
    "    rows = collections.defaultdict(list)\n",
    "    cols = collections.defaultdict(list)\n",
    "    # constructing the \"graph\" structure\n",
    "    for i, j in stones:\n",
    "        # {i: [j1, j2], j1:[i]} => like a graph\n",
    "        rows[i].append(j)\n",
    "        cols[j].append(i)\n",
    "    for i, j in stones:\n",
    "        if (i, j) in points:\n",
    "            dfs_helper(i, j)\n",
    "            island += 1\n",
    "    return len(stones) - island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stones= [[0,0],[0,1],[1,0],[1,2],[2,1],[2,2]]\n",
    "removeStones(stones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 684 redundant connection </b>  \n",
    "using union-find structure to detect which one will cause a cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRedundantConnection(edges):\n",
    "    \"\"\"union find problem, to detect if adding something will create a loop\"\"\"\n",
    "    # recall in the tutorial video, the way of using an array to save what is the root parent of each node\n",
    "    # initiate a list with index corresponding to 1 to N, the position 0 is an extra useless one\n",
    "    # at beginning, each node is indepent, parent is iteself\n",
    "    parent = [x for x in range(len(edges)+1)]\n",
    "    def find(x):\n",
    "        \"\"\"path compression\"\"\"\n",
    "        # to find the final root parent recursively\n",
    "        if parent[x]!=x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "    def union(x, y):\n",
    "        root_x = find(x)\n",
    "        root_y = find(y)\n",
    "        if root_x == root_y:\n",
    "            # find two nodes x and y actually will create a loop\n",
    "            return True\n",
    "        # assinging root of y to be the final root of root_x, the union action to add this pair to the set\n",
    "        # constructing the node to the set\n",
    "        parent[root_x] = root_y \n",
    "\n",
    "    result = []  # to make sure the last valid answer is returned\n",
    "    for x, y in edges:\n",
    "        if union(x, y):\n",
    "            result = [x,y]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = [[1,2], [1,3], [2,3]]\n",
    "findRedundantConnection(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding union-by-rank optimization, to choose the node with more elements as the root, it suppose to speed up the finding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRedundantConnection(edges):\n",
    "    \"\"\"union find problem, to detect if adding something will create a loop\"\"\"\n",
    "    # recall in the tutorial video, the way of using an array to save what is the root parent of each node\n",
    "    # to create a list with index corresponding to 1 to N, the position 0 is an extra useless one\n",
    "    parent = [x for x in range(len(edges)+1)]\n",
    "    rank = [0]*(len(edges)+1)\n",
    "    def find(x):\n",
    "        # to find the final root parent recursively\n",
    "        if parent[x]!=x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "    def union(x, y):\n",
    "        root_x = find(x)\n",
    "        root_y = find(y)\n",
    "        if root_x == root_y:\n",
    "            # find two nodes x and y actually will create a loop\n",
    "            return True\n",
    "        # assinging root of y to be the final root of root_x, the union action to add this pair to the set\n",
    "        elif rank[root_x] > rank[root_y]:\n",
    "            # root_x has more children elements than root_y\n",
    "            parent[root_y] = root_x\n",
    "        elif rank[root_y] > rank[root_x]:\n",
    "            parent[root_x] = root_y \n",
    "        else:\n",
    "            parent[root_y] = root_x\n",
    "            rank[root_x]+=1\n",
    "\n",
    "    result = []\n",
    "    for x, y in edges:\n",
    "        if union(x, y):\n",
    "            result = [x,y]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1462 Course Schedule IV </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a similar way to other course schedule problem.  \n",
    "It is much quicker than the following way.\n",
    "\n",
    "Time: O(P * N), N for topological sort and P for passing all prerequisites.\n",
    "Space: O(N^2) for all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def checkIfPrerequisite(n, prerequisites, queries):\n",
    "    graph = collections.defaultdict(list) # save {pre: [course]}\n",
    "    degree = [0]*n # for how many prequisites needed for course at index i\n",
    "    pres = [set() for _ in range(n)] # save what prerequistes are for each of the course denoted as index i. for example, course i (the index) has a set of prerequisites.\n",
    "\n",
    "    for pre, course in prerequisites:\n",
    "        graph[pre].append(course)\n",
    "        degree[course]+=1\n",
    "        pres[course].add(pre)\n",
    "\n",
    "    queue = collections.deque(course for course, d in enumerate(degree) if d==0)\n",
    "    while queue:\n",
    "        pre = queue.popleft()\n",
    "        for course in graph[pre]:\n",
    "            degree[course]-=1\n",
    "            # union operation, get distincts prerequisites set for course\n",
    "            # course's preresites's prefrequisists are the course's prerequisites too\n",
    "            pres[course] = pres[course] | pres[pre]\n",
    "            if degree[course] == 0:\n",
    "                # no more prerequisites needed, able to be taken next\n",
    "                queue.append(course)\n",
    "    # the check operation in set is O(1)\n",
    "    return [pre in pres[course] for pre, course in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "prerequisites = [[0,1],[1,2],[2,3],[3,4]]\n",
    "queries = [[0,4],[4,0],[1,3],[3,0]]\n",
    "checkIfPrerequisite(n, prerequisites, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way  \n",
    "\n",
    "a graph problem, to check if two nodes are connected in a particular direction. It is a directed graph. Floyd-Warshall O(n^3) is an algorithm that will output the minium distance of any vertices.\n",
    "construct a n*n matrix to store the relationship between each node, [i][j] means from i to j, with direction information, is different from [j][i]\n",
    "Time complexity O(N^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfPrerequisite(n, prerequisites, queries):\n",
    "    '''a graph problem, to check if two nodes are connected in a particular direction\n",
    "    construct a n*n matrix to store the relationship between each node, [i][j] means from i to j, with direction information, is different from [j][i]\n",
    "    O(N^3)\n",
    "    '''\n",
    "    matrix = [[False]*n for _ in range(n)]\n",
    "    # add the obvious prerequisites relationship to the matrix \n",
    "    for i, j in prerequisites:\n",
    "        matrix[i][j] = True\n",
    "    # add indirect prerequisites relationship to the matrix\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                matrix[i][j] = matrix[i][j] or (matrix[i][k] and matrix[k][j])\n",
    "\n",
    "    res = [matrix[i][j] for i, j in queries]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, False]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "prerequisites = [[0,1],[1,2],[2,3],[3,4]]\n",
    "queries = [[0,4],[4,0],[1,3],[3,0]]\n",
    "checkIfPrerequisite(n, prerequisites, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 332 reconstruct itineray </b>\n",
    "\n",
    "DFS way, together using sort to ensure the lexical order.  \n",
    "the graph object: {'start airport' : [a list of airport in reverse lexical order]} when pop, airport with smaller lexical order will be visited first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def findItinerary(tickets):\n",
    "    \"\"\"DFS\"\"\"\n",
    "    graph = defaultdict(list)\n",
    "    for a, b in sorted(tickets, reverse=True):\n",
    "        # sort tickets so {a:[b]} [b] is in reversed lexical order, when pop, airport with smaller lexical order will be visited first\n",
    "        graph[a].append(b)\n",
    "    route = []\n",
    "    def visit(airport):\n",
    "        \"\"\"airport: str\n",
    "        the DFS helper\n",
    "        \"\"\"\n",
    "        while graph[airport]:\n",
    "            visit(graph[airport].pop())\n",
    "        route.append(airport)\n",
    "        # the route append the airport from the bottom of the graph, so at last need to reverse it back\n",
    "\n",
    "    visit('JFK')\n",
    "    return route[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JFK', 'ATL', 'JFK', 'SFO', 'ATL', 'SFO']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets = [[\"JFK\",\"SFO\"],[\"JFK\",\"ATL\"],[\"SFO\",\"ATL\"],[\"ATL\",\"JFK\"],[\"ATL\",\"SFO\"]]\n",
    "findItinerary(tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testground",
   "language": "python",
   "name": "testground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
